}
</style>
<!-- Styles for R syntax highlighter -->
<style type="text/css">
pre .operator,
pre .paren {
color: rgb(104, 118, 135)
}
pre .literal {
color: rgb(88, 72, 246)
}
pre .number {
color: rgb(0, 0, 205);
}
pre .comment {
color: rgb(76, 136, 107);
}
pre .keyword {
color: rgb(0, 0, 255);
}
pre .identifier {
color: rgb(0, 0, 0);
}
pre .string {
color: rgb(3, 106, 7);
}
</style>
<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<h1>Practical Machine Learning Assignment</h1>
<p>The data consists of a set of readings from sensors attached to subjects performing a variety of exercises. The task is to build a model which will correctly classify activities, given unlabelled sets of readings.</p>
<p>Load the <a href="http://caret.r-forge.r-project.org/">Caret</a> library and set the random number generator&#39;s seed, to ensure reproducibility:</p>
<pre><code class="r">library(caret)
set.seed(1234)
</code></pre>
<h2>Reading and Cleaning the Data</h2>
<p>Read the data, inserting NAs from the string &ldquo;NA&rdquo; and empty fields; trim whitespace in other fields so R treats them correctly as numeric.</p>
<pre><code class="r">rawData &lt;- read.csv(&quot;pml-training.csv&quot;, na.strings=c(&quot;NA&quot;,&quot;&quot;), strip.white=T)
dim(rawData)
</code></pre>
<pre><code>## [1] 19622   160
</code></pre>
<p>The data frame returned by reading the file has nearly 20,000 rows and 160 columns so ruthlessly discard any column with an NA, as well as metadata and time-related ones.</p>
<pre><code class="r">isNA &lt;- apply(rawData, 2, function(x) { sum(is.na(x)) })
validData &lt;- subset(rawData[, which(isNA == 0)],
select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
dim(validData)
</code></pre>
<pre><code>## [1] 19622    53
</code></pre>
<p>OK, so we&#39;ve got rid of 2/3s of the columns. Let&#39;s partition the data into training and test sets. (The <em>classe</em> column is the outcome &mdash; the dataset was from <a href="http://groupware.les.inf.puc-rio.br/har">Brazil</a>.)</p>
<pre><code class="r">inTrain &lt;- createDataPartition(validData$classe, p=0.7, list=F)
training &lt;- validData[inTrain,]
testing &lt;- validData[-inTrain,]
</code></pre>
<h2>Training a Random Forest Model</h2>
<p>Now train a <a href="https://en.wikipedia.org/wiki/Random_forest">Random Forest</a> model on the training set. (Using this particular combination of <em>trControl</em> parameters is important, as by default bootstrapping is used, which is very time-intensive.)</p>
<pre><code class="r">ctrl &lt;- trainControl(allowParallel=T, method=&quot;cv&quot;, number=4)
model &lt;- train(classe ~ ., data=training, model=&quot;rf&quot;, trControl=ctrl)
pred &lt;- predict(model, newdata=testing)
</code></pre>
<p>Check the predictions against the held-back test-set.</p>
<pre><code class="r">sum(pred == testing$classe) / length(pred)
</code></pre>
<pre><code>## [1] 0.9942
</code></pre>
<pre><code class="r">confusionMatrix(testing$classe, pred)$table
</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 1674    0    0    0    0
##          B   12 1126    1    0    0
##          C    0    4 1018    4    0
##          D    0    1    5  957    1
##          E    0    1    2    3 1076
</code></pre>
<p>So our trained model is 99.4% accurate against our test-set and this is confirmed by the confusion matrix. Let&#39;s use this super-accurate model to predict the unknown labels.</p>
<pre><code class="r">rawTestData &lt;- read.csv(&quot;pml-testing.csv&quot;, na.strings=c(&quot;NA&quot;,&quot;&quot;), strip.white=T)
validTestData &lt;- subset(rawTestData[, which(isNA == 0)],
select=-c(X, user_name, new_window, num_window, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp))
predict(model, newdata=validTestData)
</code></pre>
<pre><code>## Loading required package: randomForest
## randomForest 4.6-7
## Type rfNews() to see new features/changes/bug fixes.
</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>
<p>Which variables are most important in this model?</p>
<pre><code class="r">varImp(model)
</code></pre>
<pre><code>## rf variable importance
##
##   only 20 most important variables shown (out of 52)
##
##                      Overall
## roll_belt              100.0
## pitch_forearm           58.3
## yaw_belt                55.8
## magnet_dumbbell_y       44.5
## pitch_belt              43.8
## magnet_dumbbell_z       42.3
## roll_forearm            39.0
## accel_dumbbell_y        20.7
## roll_dumbbell           17.4
## magnet_dumbbell_x       16.4
## accel_forearm_x         16.1
## magnet_belt_z           15.8
## total_accel_dumbbell    14.4
## magnet_forearm_z        13.3
## accel_dumbbell_z        12.6
## magnet_belt_y           12.3
## accel_belt_z            12.0
## yaw_arm                 11.2
## gyros_belt_z            10.9
## magnet_belt_x           10.3
</code></pre>
<h2>Training a smaller Random Forest Model</h2>
<p>Let&#39;s train and test a simpler model using only the top-ten most-important predictors.</p>
<pre><code class="r">smallValidData &lt;- subset(validData,
select=c(roll_belt, pitch_forearm, yaw_belt, magnet_dumbbell_y, pitch_belt, magnet_dumbbell_z, roll_forearm, accel_dumbbell_y, roll_dumbbell, magnet_dumbbell_x,classe))
smallModel &lt;- train(classe ~ ., data=smallValidData[inTrain,], model=&quot;rf&quot;, trControl=ctrl)
</code></pre>
<p>This is 5x faster and gets the same (correct) answer. Its accuracy on the test set is 98.5%.</p>
<pre><code class="r">predict(smallModel, newdata=validTestData)
</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>
<pre><code class="r">smallPred &lt;- predict(smallModel, newdata=testing)
sum(smallPred == testing$classe) / length(smallPred)
</code></pre>
<pre><code>## [1] 0.9845
</code></pre>
<pre><code class="r">confusionMatrix(testing$classe, smallPred)$table
</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 1665    2    6    1    0
##          B   16 1098   13   10    2
##          C    1   11 1008    6    0
##          D    0    1    3  959    1
##          E    0    8    6    4 1064
</code></pre>
<h2>Training a Support Vector Machine</h2>
<p>Just for the hell of it, let&#39;s train an SVM on the top-ten predictors.</p>
<pre><code class="r">svm &lt;- train(classe ~ ., data=smallValidData[inTrain,], model=&quot;svm&quot;, trControl=ctrl)
svmPred &lt;- predict(svm, newdata=testing)
sum(svmPred == testing$classe) / length(svmPred)
</code></pre>
<pre><code>## [1] 0.9844
</code></pre>
<pre><code class="r">confusionMatrix(testing$classe, svmPred)$table
</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 1663    4    5    2    0
##          B   16 1099   13    9    2
##          C    1   10 1009    6    0
##          D    0    1    3  959    1
##          E    0   10    6    3 1063
</code></pre>
<p>It also scores 98.4% accuracy and its confusion matrix is only slightly less accurate than the simpler Random Forest model&#39;s.</p>
</body>
</html>
dim(dataset)
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<head>
<title>Practical Machine Learning Assignement Write-Up</title>
</head>
<body>
<p>This report explains my approach of this assignement.</p>
<p>Step 1: Loading the data:</p>
<!--begin.rcode
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset)
end.rcode-->
<p>You can also embed plots, for example:</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->
</body>
</html>
<html>
<html>
<head>
<title>Practical Machine Learning Assignment</title>
</head>
<body>
<p>This document sums up what I have done on the programming assignment for the course "Practical Machine Learning" on Coursera</p>
<h1>Step 0:</h1>
<p>Let's first import the library we will use. </p>
<!--begin.rcode
library(lattice); library(ggplot2); library(caret);library(kernlab); library(randomForest)
end.rcode-->
<p>And let's fix the seed to make the experience reproductive. </p>
<!--begin.rcode
set.seed(32323)
end.rcode-->
<h1>Step 1: Loading the data</h1>
<p>Let's load the train and test datasets.</p>
<!--begin.rcode
# Load the training dataset:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=TRUE)
dim(dataset)
# Load the test dataset
dataset_test <- read.csv("pml-testing.csv", na.strings=c("NA",""), strip.white=T)
dim(dataset_test)
end.rcode-->
<p>We have <b>19622 training examples</b> composed of the recording of <b>160 measures</b>. <br/>
We have <b>20 test examples</b>.</p>
<h1>Step 2: Cleaning the data</h1>
<p>By looking at the data we can notice that there are a lot of empty columns.<br/>
Let's remove them. </p>
<!--begin.rcode
# Cleaning the data:
isNA <- apply(dataset, 2, function(x) { sum(is.na(x)) })
# For the training dataset:
dataset <- subset(dataset[, which(isNA == 0)],
select=-c(X, user_name, new_window, num_window,
raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp))
dim(dataset)
# For the test dataset:
dataset_test <- subset(dataset_test[, which(isNA == 0)],
select=-c(X, user_name, new_window, num_window,
raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp))
end.rcode-->
<p>We have reduced the training set to <b>19622 training examples</b> composed of the recording of <b>53 usable measures</b>.</p>
<h1>Step 3: Creation of the training set and validation set</h1>
<p>In order to measure the performances of our future predictor we split the dataset into a training set and a validation set. The first one will be used to train the predictor, while the second one will be used to assess the performances.<br/>
The split used is: <b>80% </b> for the training set and <b>20%</b> for the validation set.</p>
<!--begin.rcode
# Spliting the dataset:
inTrain <- createDataPartition(dataset$classe, p=0.8, list=FALSE)
train_set <- dataset[inTrain,]
valid_set <- dataset[-inTrain,]
end.rcode-->
<h1>Step 4: Training some predictors</h1>
<h2> Test 1: Random Forest:</h1>
<p>We first try an powerful yet easy to parametrize predictor to have an idea of what performance could be obtained. <br/>
We train a <b>Random Forest Classifier</b>.</p>
<!--begin.rcode
# Test 1: Random forest classifier:
ctrl <- trainControl(allowParallel=TRUE, method="cv", number=4)
model <- train(classe ~ ., data=train_set, model="rf", trControl=ctrl)
predictor <- predict(model, newdata=valid_set)
end.rcode-->
<p>Let's now assess the generalization performance of this classifier by computing the error made on the validation set.</p>
<!--begin.rcode
# Error on valid_set:
sum(predictor == valid_set$classe) / length(predictor)
confusionMatrix(valid_set$classe, predictor)$table
end.rcode-->
<p>We have a validation error of <b>99.29%</b>.<br/>
We can consider this classifier as good.</p>
<p>Let's see what are the prediction for the test set.</p>
<!--begin.rcode
# Prediction on the test set:
predict(model, newdata=dataset_test)
end.rcode-->
<p>We have the following prediction: <br/>
<b>  B A B A A E D B A A B C B A E E A B B B </b></p>
<h2> Test 2: SVM on lower dimension training examples</h1>
<p>The random forest appears to be a good predictor but it is quite slow to train on the 53 dimensions vectors of our dataset. <br/>
Let's assess the performance of an SVM trained only on the ten most important parameters. <br/>
We train a <b>SVM Classifier</b>.</p>
<!--begin.rcode
# Most important variable for the ramdom forest predictor:
varImp(model)
# Let us reduce the training dataset to those ten variables
dataset_small <- subset(dataset,
select=c(roll_belt, pitch_forearm, yaw_belt,
magnet_dumbbell_y, pitch_belt,
magnet_dumbbell_z, roll_forearm,
accel_dumbbell_y, roll_dumbbell,
magnet_dumbbell_x,classe))
dim(dataset_small)
end.rcode-->
<p>We now have <b>19622 training examples</b> composed of the recording of <b>10 measures</b>. (11th parammeter is the class)</p>
<p>Let's train the SVM on this "small" dataset.</p>
<!--begin.rcode
# Training an SVM on the small dataset
svm <- train(classe ~ ., data=dataset_small[inTrain,], model="svm", trControl=ctrl)
predictor_svm <- predict(svm, newdata=valid_set)
end.rcode-->
<p>Let's now assess the generalization performance of this classifier by computing the error made on the validation set.</p>
<!--begin.rcode
# Error on valid_set:
sum(predictor_svm == valid_set$classe) / length(predictor_svm)
confusionMatrix(valid_set$classe, predictor_svm)$table
end.rcode-->
<p>We have a validation error of <b>98.45%</b>.<br/>
The performance are slightly lower but the training is way faster. <br/>
Depending on the application the trade-off could be interesting</p>
<p>Let's see what are the prediction for the test set.</p>
<!--begin.rcode
# Prediction on the test set:
predict(model, newdata=dataset_test)
end.rcode-->
<p>We have the following prediction: <br/>
<b> B A B A A E D B A A B C B A E E A B B B </b> <br/>
We have the same prediction with the random forest trained on the full dataset and with the SVM trained with the reduced dataset. Again the trade-off "speed of training versus "classification performances" could be interesting depending on the application.</p>
</body>
</html>
library(caret);library(kernlab)
set.seed(32323)
# Load the test file:
dataset  <- read.csv("pml-training.csv", na.strings=c("NA",""), strip.white=TRUE)
dim(dataset)
# Cleaning the data:
isNA <- apply(dataset, 2, function(x) { sum(is.na(x)) })
dataset <- subset(dataset[, which(isNA == 0)],
select=-c(X, user_name, new_window, num_window,
raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp))
dim(dataset)
# Spliting the dataset:
inTrain <- createDataPartition(dataset$classe, p=0.75, list=FALSE)
train_set <- dataset[inTrain,]
valid_set <- dataset[-inTrain,]
# Test 1: Random forest classifier:
ctrl <- trainControl(allowParallel=TRUE, method="cv", number=4)
model <- train(classe ~ ., data=train_set, model="rf", trControl=ctrl)
predictor <- predict(model, newdata=valid_set)
# Error on valid_set:
sum(predictor == valid_set$classe) / length(predictor)
confusionMatrix(valid_set$classe, predictor)$table
# Classification for test_set:
dataset_test <- read.csv("pml-testing.csv", na.strings=c("NA",""), strip.white=T)
dataset_test <- subset(dataset_test[, which(isNA == 0)],
select=-c(X, user_name, new_window, num_window,
raw_timestamp_part_1, raw_timestamp_part_2,
cvtd_timestamp))
predict(model, newdata=dataset_test)
# Test 2: SVM:
# Most important variable for the ramdom forest predictor:
varImp(model)
# Let us train the SVM on the dataset reduce to those ten variables
dataset_small <- subset(dataset,
select=c(roll_belt, pitch_forearm, yaw_belt,
magnet_dumbbell_y, pitch_belt,
magnet_dumbbell_z, roll_forearm,
accel_dumbbell_y, roll_dumbbell,
magnet_dumbbell_x,classe))
svm <- train(classe ~ ., data=dataset_small[inTrain,], model="svm", trControl=ctrl)
predictor_svm <- predict(svm, newdata=valid_set)
# Error on valid_set:
sum(predictor_svm == valid_set$classe) / length(predictor_svm)
confusionMatrix(valid_set$classe, predictor_svm)$table
# Classification for test_set:
results <- predict(model, newdata=dataset_test)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(results)
